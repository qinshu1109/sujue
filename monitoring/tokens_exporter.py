#!/usr/bin/env python3
"""
Prometheus Tokenä½¿ç”¨é‡å¯¼å‡ºå™¨
å¥³å¨²é€ ç‰©ï¼šé‡åŒ–æ™ºèƒ½ï¼Œç²¾å‡†ç›‘æ§
"""

import time
import threading
from datetime import datetime
from typing import Dict, Any, Optional
import structlog
from prometheus_client import Counter, Histogram, Gauge, start_http_server, REGISTRY

# é…ç½®æ—¥å¿—
logger = structlog.get_logger()

class TokenMetricsExporter:
    """TokenæŒ‡æ ‡å¯¼å‡ºå™¨"""
    
    def __init__(self, port: int = 9100):
        self.port = port
        self.server_thread = None
        self.running = False
        
        # å®šä¹‰PrometheusæŒ‡æ ‡
        self.tokens_used_total = Counter(
            'tokens_used_total',
            'Total tokens consumed by the Text2SQL system',
            ['model', 'type', 'endpoint']
        )
        
        self.token_cost_usd_total = Counter(
            'token_cost_usd_total', 
            'Total cost in USD for token usage',
            ['model', 'endpoint']
        )
        
        self.query_response_time = Histogram(
            'text2sql_query_duration_seconds',
            'Time spent processing text2sql queries',
            ['endpoint', 'status'],
            buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
        )
        
        self.active_queries = Gauge(
            'text2sql_active_queries',
            'Number of currently active queries'
        )
        
        self.model_availability = Gauge(
            'text2sql_model_availability',
            'Model availability status (1=available, 0=unavailable)',
            ['model']
        )
        
        # Tokenä»·æ ¼æ˜ å°„ï¼ˆæ¯1K tokensçš„USDä»·æ ¼ï¼‰
        self.token_prices = {
            'claude-3-opus-20240229': {
                'input': 0.015,   # $15/1M input tokens
                'output': 0.075   # $75/1M output tokens
            },
            'claude-3-sonnet-20240229': {
                'input': 0.003,   # $3/1M input tokens
                'output': 0.015   # $15/1M output tokens
            },
            'claude-3-haiku-20240307': {
                'input': 0.00025, # $0.25/1M input tokens
                'output': 0.00125 # $1.25/1M output tokens
            }
        }
        
        logger.info("TokenMetricsExporteråˆå§‹åŒ–å®Œæˆ", port=self.port)
    
    def record_token_usage(self, 
                          model: str,
                          input_tokens: int,
                          output_tokens: int, 
                          endpoint: str = "text2sql"):
        """è®°å½•Tokenä½¿ç”¨é‡"""
        try:
            # è®°å½•è¾“å…¥tokens
            self.tokens_used_total.labels(
                model=model,
                type="input", 
                endpoint=endpoint
            ).inc(input_tokens)
            
            # è®°å½•è¾“å‡ºtokens
            self.tokens_used_total.labels(
                model=model,
                type="output",
                endpoint=endpoint
            ).inc(output_tokens)
            
            # è®¡ç®—æˆæœ¬
            if model in self.token_prices:
                input_cost = (input_tokens / 1000) * self.token_prices[model]['input']
                output_cost = (output_tokens / 1000) * self.token_prices[model]['output']
                total_cost = input_cost + output_cost
                
                self.token_cost_usd_total.labels(
                    model=model,
                    endpoint=endpoint
                ).inc(total_cost)
                
                logger.info("Tokenä½¿ç”¨é‡å·²è®°å½•",
                           model=model,
                           input_tokens=input_tokens,
                           output_tokens=output_tokens,
                           cost_usd=round(total_cost, 6),
                           endpoint=endpoint)
            else:
                logger.warning("æœªçŸ¥æ¨¡å‹ä»·æ ¼", model=model)
                
        except Exception as e:
            logger.error(f"è®°å½•Tokenä½¿ç”¨é‡å¤±è´¥: {e}")
    
    def record_query_time(self, endpoint: str, status: str, duration: float):
        """è®°å½•æŸ¥è¯¢å“åº”æ—¶é—´"""
        self.query_response_time.labels(
            endpoint=endpoint,
            status=status
        ).observe(duration)
    
    def set_active_queries(self, count: int):
        """è®¾ç½®å½“å‰æ´»è·ƒæŸ¥è¯¢æ•°"""
        self.active_queries.set(count)
    
    def set_model_availability(self, model: str, available: bool):
        """è®¾ç½®æ¨¡å‹å¯ç”¨æ€§"""
        self.model_availability.labels(model=model).set(1 if available else 0)
    
    def start_server(self):
        """å¯åŠ¨Prometheus HTTPæœåŠ¡å™¨"""
        if self.running:
            logger.warning("ExporteræœåŠ¡å™¨å·²åœ¨è¿è¡Œ")
            return
        
        try:
            def run_server():
                start_http_server(self.port)
                logger.info(f"PrometheusæŒ‡æ ‡æœåŠ¡å™¨å¯åŠ¨", port=self.port)
                while self.running:
                    time.sleep(1)
            
            self.running = True
            self.server_thread = threading.Thread(target=run_server, daemon=True)
            self.server_thread.start()
            
            # åˆå§‹åŒ–ä¸€äº›åŸºç¡€æŒ‡æ ‡
            for model in self.token_prices.keys():
                self.set_model_availability(model, True)
            
            logger.info("TokenMetricsExporteræœåŠ¡å¯åŠ¨æˆåŠŸ", 
                       endpoint=f"http://localhost:{self.port}/metrics")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨ExporteræœåŠ¡å™¨å¤±è´¥: {e}")
            self.running = False
    
    def stop_server(self):
        """åœæ­¢æœåŠ¡å™¨"""
        if self.running:
            self.running = False
            logger.info("TokenMetricsExporteræœåŠ¡åœæ­¢")
    
    def get_current_metrics(self) -> Dict[str, Any]:
        """è·å–å½“å‰æŒ‡æ ‡å¿«ç…§"""
        try:
            from prometheus_client import generate_latest
            metrics_data = generate_latest(REGISTRY).decode('utf-8')
            
            # è§£ætokens_used_totalæŒ‡æ ‡
            token_metrics = {}
            for line in metrics_data.split('\n'):
                if line.startswith('tokens_used_total'):
                    token_metrics[line] = True
            
            return {
                'timestamp': datetime.utcnow().isoformat(),
                'metrics_endpoint': f"http://localhost:{self.port}/metrics",
                'token_metrics_count': len(token_metrics),
                'server_running': self.running
            }
            
        except Exception as e:
            logger.error(f"è·å–æŒ‡æ ‡å¿«ç…§å¤±è´¥: {e}")
            return {}

# å…¨å±€å®ä¾‹
_exporter_instance = None

def get_exporter(port: int = 9100) -> TokenMetricsExporter:
    """è·å–å…¨å±€Exporterå®ä¾‹"""
    global _exporter_instance
    if _exporter_instance is None:
        _exporter_instance = TokenMetricsExporter(port)
    return _exporter_instance

def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    exporter = get_exporter(9100)
    exporter.start_server()
    
    # æ¨¡æ‹Ÿä¸€äº›æ•°æ®
    print("ğŸš€ å¯åŠ¨TokenæŒ‡æ ‡æµ‹è¯•...")
    
    # æ¨¡æ‹ŸæŸ¥è¯¢
    exporter.record_token_usage(
        model="claude-3-opus-20240229",
        input_tokens=150,
        output_tokens=45,
        endpoint="text2sql"
    )
    
    exporter.record_token_usage(
        model="claude-3-sonnet-20240229", 
        input_tokens=200,
        output_tokens=60,
        endpoint="validate"
    )
    
    exporter.record_query_time("text2sql", "success", 1.5)
    exporter.set_active_queries(3)
    
    print(f"ğŸ“Š æŒ‡æ ‡å·²è®°å½•ï¼Œè®¿é—®: http://localhost:9100/metrics")
    print("ğŸ” æµ‹è¯•å‘½ä»¤: curl localhost:9100/metrics | grep tokens_used_total")
    
    # ä¿æŒè¿è¡Œ
    try:
        while True:
            time.sleep(10)
            # æ¨¡æ‹Ÿæ›´å¤šæ•°æ®
            exporter.record_token_usage(
                model="claude-3-haiku-20240307",
                input_tokens=100, 
                output_tokens=30,
                endpoint="text2sql"
            )
            
    except KeyboardInterrupt:
        print("\nâš ï¸ åœæ­¢æœåŠ¡...")
        exporter.stop_server()

if __name__ == "__main__":
    main()